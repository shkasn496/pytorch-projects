{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "import torch.nn as nn # all neural network modules, nn.Linear, nn.Conv2d, BatchNorm, loss functions\n",
    "import torch.optim as optim # all optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F # all functions that dont have any parameters eg: activations like relu\n",
    "from torch.utils.data import Dataset, DataLoader # gives easier dataset management and creates mini batches\n",
    "import torchvision.datasets as datasets # standard public datasets\n",
    "import torchvision.transforms as transforms # transforms on dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "INPUT_CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "RESIZE_WIDTH = 224\n",
    "RESIZE_HEIGHT = 224\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply data transforms for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[0.4941781  0.4851347  0.45040762] [0.24667414 0.24295948 0.2616299 ]\n"
     ]
    }
   ],
   "source": [
    "# 1. Get mean and std deviation of my dataset\n",
    "test_dataset = datasets.CIFAR10(root=\"dataset/\", train=False, transform=transforms.ToTensor(),\n",
    "                                download=True)\n",
    "loader = DataLoader(dataset=test_dataset, batch_size=64)\n",
    "def get_mean_std(loader):\n",
    "    '''Calculate mean for input channels and std dev for input channels'''\n",
    "    # std_dev = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in loader:\n",
    "        ''' We have an input that is (N, C, H, W) where N is the number of examples in our batch,\n",
    "        C the number of channels and H, W the height and width. \n",
    "        We want to have the mean (of each channel) across all examples, all the height pixels and width pixels. \n",
    "        This is why I specify dim=[0,2,3], because we want to reduce all the other dimensions \n",
    "        except for the channels. '''\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "    std = torch.sqrt((channels_squared_sum/num_batches) - mean**2)\n",
    "    return mean.numpy(), std.numpy()\n",
    "\n",
    "MEAN, STD = get_mean_std(loader)\n",
    "print(MEAN, STD)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=(RESIZE_WIDTH,RESIZE_HEIGHT), antialias=True),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load the cifar 10 dataset\n",
    "train_dataset = datasets.CIFAR10(root=\"dataset/\", train=True, \n",
    "                                 transform=transform,\n",
    "                                  download=True)\n",
    "test_dataset = datasets.CIFAR10(root=\"dataset/\", train=False, \n",
    "                                transform=transform,\n",
    "                                download=True)\n",
    "\n",
    "# Instantiate loader objects to facilitate processing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our CNN class extending from nn.module\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        ''' define the layers of the network '''\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=32,\n",
    "                               kernel_size=(3,3)) # 32 x 222 x 222\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.conv1.out_channels, out_channels=32,\n",
    "                               kernel_size=(3,3)) # 32 x 220 x 220\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)) # 32 x 110 x 110\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=self.conv2.out_channels, out_channels=64,\n",
    "                               kernel_size=(3,3)) # 64 x 108 x 108\n",
    "        self.conv4 = nn.Conv2d(in_channels=self.conv3.out_channels, out_channels=64,\n",
    "                               kernel_size=(3,3)) # 64 x 106 x 106\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)) # 64 x 53 x 53\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=self.conv4.out_channels * 53 * 53,\n",
    "                             out_features= 53 * 53)\n",
    "        self.fc2 = nn.Linear(in_features=self.fc1.out_features, out_features=num_classes)\n",
    "        return\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ''' progresses the data across the layers '''\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.pool1(out)\n",
    "\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = self.pool2(out)\n",
    "\n",
    "        # need to flatten conv features from NxCxHxW to Nxfeatures before sending to fc block\n",
    "        out = out.reshape(out.shape[0], -1) # same as out = out.view(out.shape[0], -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out) # N x num_classes\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the CNN on dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(input_channels=INPUT_CHANNELS, num_classes=NUM_CLASSES).to(device)\n",
    "dummy_data = torch.rand(size=(BATCH_SIZE, INPUT_CHANNELS, RESIZE_HEIGHT, RESIZE_WIDTH)).to(device)\n",
    "model(dummy_data).shape # BATCH_SIZE x NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    avg_train_loss = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            # push data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            logits = model(data)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Clean the previous gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backpropagation from loss, calculate new gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights by stepping in direction of min gradients\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_train_loss.append(train_loss/BATCH_SIZE)\n",
    "        scheduler.step(train_loss/BATCH_SIZE)\n",
    "        if epoch % 2 ==0:\n",
    "            print(f\"Epoch : {epoch},  Train Loss: {train_loss:.2f}\")\n",
    "\n",
    "    return avg_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    model.eval()\n",
    "    correct_samples, total_samples, avg_test_loss = 0, 0, 0\n",
    "    n_iterations = math.ceil(len(test_dataset)/BATCH_SIZE)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # push data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            logits = model(data)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, target)\n",
    "            avg_test_loss += loss.item()\n",
    "\n",
    "            # Get the class\n",
    "            pred = torch.argmax(input=torch.softmax(data), dim=1)\n",
    "            correct_samples += (target == pred).sum()\n",
    "            total_samples += target.shape[1]\n",
    "    \n",
    "    avg_test_loss /= n_iterations\n",
    "\n",
    "    accuracy = correct_samples / total_samples\n",
    "\n",
    "    return avg_test_loss, accuracy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy test- Overfit on a small sample of train data to check if the model works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(train_loader))\n",
    "epoch_train_loss =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9967415028077085e-06\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-04.\n",
      "7.748580514999048e-07\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-05.\n",
      "0.0\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.0000e-06.\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m \u001b[39m# Update weights by stepping in direction of min gradients\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     24\u001b[0m scheduler\u001b[39m.\u001b[39mstep(loss)\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/adam.py:344\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    341\u001b[0m     param \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mview_as_real(param)\n\u001b[1;32m    343\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 344\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[1;32m    345\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# overfit on 1 batch of training data\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    # push data to device\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Forward propagation\n",
    "    logits = model(data)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = criterion(logits, target)\n",
    "    train_loss = loss.item()\n",
    "\n",
    "    # Clean the previous gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backpropagation from loss, calculate new gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights by stepping in direction of min gradients\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "    if epoch % 5 ==0:\n",
    "        print(train_loss)\n",
    "    epoch_train_loss.append(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGwCAYAAACHJU4LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5UklEQVR4nO3de5DU9Z3v/9e3u6cvw1y4DggMiHJx0YARTDJqIkalFu/n1JbZeIl7NL+UGzQqWVNRk02iFceyNq6xUBKzHt3Ek8JsXI0nrK7krGAMkgCGSNTlEhBQhAGEuXfPdPf390fPt7sH5tLd8711z/NRNYGZ6Zn5QBvmNZ/P+/3+GKZpmgIAAPChgNcLAAAAGAxBBQAA+BZBBQAA+BZBBQAA+BZBBQAA+BZBBQAA+BZBBQAA+FbI6wWMRDqd1oEDB1RbWyvDMLxeDgAAKIBpmmpvb9fUqVMVCAy9Z1LWQeXAgQNqbGz0ehkAAKAE+/fv1/Tp04d8TFkHldraWkmZP2hdXZ3HqwEAAIVoa2tTY2Nj9vv4UMo6qFjHPXV1dQQVAADKTCFlGxTTAgAA3yKoAAAA3yKoAAAA3yKoAAAA3yKoAAAA3yKoAAAA3yKoAAAA3yKoAAAA3yKoAAAA3yKoAAAA3yKoAAAA3yKoAAAA3yKojFBPMu31EgAAqFgElRFY8/ZHOuPbL+v5LR94vRQAACoSQWUE3tx9RGlT+uH/26l02vR6OQAAVByCygi0diclSfs+7tL6nYc9Xg0AAJWHoDICrd292d//7M29Hq4EAIDKRFAZgba8oPLa9hbt/7jLw9UAAFB5CCojYAWVcdVVMk3p2Y3sqgAAYCeCyghYRz+3XDBLkvTc5v2K96a8XBIAABWFoFIi0zSzQeXqs6dp2tiYjnf16v/+6YDHKwMAoHL4Jqg0NzfLMAzdeeedXi+lIF09KSX7WpLHjwnr+s/MkMTxDwAAdvJFUNm0aZOefPJJLViwwOulFMzaTQkFDFWHg/rC4kaFgwH96YNW/Wn/cW8XBwBAhfA8qHR0dOj666/XT37yE40bN27IxyYSCbW1tfV78YoVVOpjVTIMQxNqIrpiwSmSpJ/SqgwAgC08DyrLly/X5ZdfrksuuWTYxzY3N6u+vj770tjY6MIKB5YfVCw3Ns2UJP3ftw/o484eT9YFAEAl8TSorF69Wm+99Zaam5sLevw999yj1tbW7Mv+/fsdXuHgrNbkurygcnbjWJ01rU49ybR+sdm7tQEAUCk8Cyr79+/XHXfcoWeffVbRaLSgj4lEIqqrq+v34pXWAYKKYRj60mdOlZQpqk1x/w8AACPiWVDZsmWLWlpatGjRIoVCIYVCIa1fv16PPfaYQqGQUil/zyMZ6OhHkq5cOFX1sSp9cKxb63e0eLE0AAAqhmdB5eKLL9a2bdu0devW7MvixYt1/fXXa+vWrQoGg14trSBt2aAS6vf2WDioaxdPl0RRLQAAIxUa/iHOqK2t1VlnndXvbWPGjNGECRNOersfDbajIknXf3qmfvLbPVq/47D2Hu3UzAlj3F4eAAAVwfOun3I1VFA5deIYXTh3Evf/AAAwQr4KKuvWrdOjjz7q9TIKMlRQkaQv9bUq/2LzB+ru8Xe9DQAAfuWroFJOhgsqS+Y1aPq4mFq7uf8HAIBSEVRK1BZPSurfnpwvGDB0w2cyuyo/3fi+TJNWZQAAikVQKdFwOyqSdO3iRoVDAf35wzZt5f4fAACKRlApUXbgW3TwoDJ+TDh7/8/PaFUGAKBoBJUSxHtT6kmmJUn11YMHFUn6UtOpkqRfv/2RjnYknF4aAAAVhaBSAms3JWBINeGhR9Gc3ThW80+pU08qrTd2HXFjeQAAVAyCSgny7/kJBIxhHz93co0k6VBb3NF1AQBQaQgqJSikkDbfpNqIJKmljaMfAACKQVApQWtXcUGloTZzO/RhalQAACgKQaUEbfEig0odOyoAAJSCoFKC/BqVQkyq6Qsq7dSoAABQDIJKCQqZoZIvu6PSzo4KAADFIKiUoPhi2kyNSns8qXgvFxQCAFAogkoJig0qddGQwqHMX/VhdlUAACgYQaUEbUUGFcMw1FBLnQoAAMUiqJSg2B0VSdmgwo4KAACFI6iUoJSgkh36RlABAKBgBJUSlLajkimoZZYKAACFI6iUoK07KYmjHwAAnEZQKVJPMq3uvhbj0o5+KKYFAKBQBJUiWcc+klQTDRX8cQx9AwCgeASVIllBpTYaUjBgFPxx2YsJCSoAABSMoFKkUgpppVyNypGOhFJp0/Z1AQBQiQgqRSp22Jtl/JiwDENKm9LRTnZVAAAoBEGlSKXuqISCAU0YQ+cPAADFIKgUqdSgIilvjD5BBQCAQhBUilTq0Y+Ua1E+zNA3AAAKQlApkj07KsxSAQCgEASVIllBpa6UoFJHjQoAAMUgqBRpJEFlUg01KgAAFIOgUqQRHf3U9V1MSFABAKAgBJUi2VGjwtEPAACFIagUyY6un5b2uEyT6bQAAAyHoFKkke2oZI5+4r1ptSeStq4LAIBKRFApQjKVVmdPSlJpQSUWDqo2krlxmeMfAACGR1ApQls8twtSFw2V9Dmyxz8MfQMAYFgElSJYxz41kZBCwdL+6iYx9A0AgIIRVIqQnaFS4m6KlGtR5ugHAIDhEVSKMJJhbxZalAEAKBxBpQgj6fixTOIGZQAACkZQKYIdQYUdFQAACkdQKcJIhr1ZrFkqFNMCADA8gkoR7AgqHP0AAFA4gkoR7Dz6Od7Vq0QyZcu6AACoVASVImSDSnXpQWVsdZWqgoYk6UhHjy3rAgCgUhFUipCbo1J6UDEMQ5NqrOm01KkAADAUgkoR7Dj6kaRJdVZBLXUqAAAMhaBSBDsGvkm0KAMAUCiCShFs21Gh8wcAgIIQVAqUSptq77s9eaRBJbejQo0KAABDIagUqKMvpEh2BBUuJgQAoBAElQJZxz6xqqDCoZH9tXH0AwBAYQgqBbKrPkXKHf20tBFUAAAYCkGlQLYGlbpMUDnSkVA6bY748wEAUKkIKgXKtSaHRvy5JozJBJVk2tSxLqbTAgAwGIJKgezcUQmHAho/JiyJOhUAAIZCUCmQXcPeLAx9AwBgeASVAtm5oyLR+QMAQCEIKgVqizsVVBj6BgDAYAgqBbJ7R8Ua+kaLMgAAgyOoFKjN9qDSV6PSQVABAGAwBJUCOVWjcpgdFQAABkVQKZBTXT/UqAAAMDiCSoFsr1Gp42JCAACGQ1ApQDpt2l6jYh39dPak1JlIDvNoAABGJ4JKATp6krKu5LErqNREQqoOByUxSwUAgMEQVApg7aaEQwFFq4K2fV6m0wIAMDSCSgHsrk+xMPQNAIChEVQK4FRQYegbAABDI6gUwO5CWsskhr4BADAkT4PKqlWrtGDBAtXV1amurk5NTU16+eWXvVzSgBw/+mFHBQCAAXkaVKZPn66HHnpImzdv1ubNm/X5z39eV199td555x0vl3WS7LC3aMjWz8vQNwAAhmbvd94iXXnllf1e//73v69Vq1Zp48aNOvPMMz1a1ckcq1Fh6BsAAEPyNKjkS6VS+rd/+zd1dnaqqalpwMckEgklErlv6m1tba6szbGjnxrakwEAGIrnxbTbtm1TTU2NIpGIbr31Vr3wwguaP3/+gI9tbm5WfX199qWxsdGVNbZ1ZybH2nXPj6WhLhNUjnb2qDeVtvVzAwBQCTwPKvPmzdPWrVu1ceNG/f3f/71uuukmvfvuuwM+9p577lFra2v2Zf/+/a6s0akdlfHVYYUChiTpCJ0/AACcxPOjn3A4rNmzZ0uSFi9erE2bNumHP/yhfvzjH5/02Egkokgk4vYSHQsqgYChiTURHWyL63B7QqfUx2z9/AAAlDvPd1ROZJpmvzoUP3BqjopEizIAAEPxdEfl3nvv1bJly9TY2Kj29natXr1a69at0yuvvOLlsk6S3VGptj+o5FqUCSoAAJzI06By6NAh3Xjjjfroo49UX1+vBQsW6JVXXtGll17q5bL6MU0zb46KA0Gljs4fAAAG42lQeeqpp7z88gXp6kkpmTYlOXT0U8PQNwAABuO7GhW/sXZTQgFD1eGg7Z9/Ut/QN45+AAA4GUFlGPkdP4Zh2P75rRoVjn7gZ109SZmm6fUyAIxCBJVhONnxI+XdoExQgU+9f6RTn7x/rb714p+9XgqAUYigMoxsIa1DQSV/R4WfWOFH737UpkQyrbf2Hfd6KQBGIYLKMJwa9maxdlR6Uuns1wL8pLsnJUmK96Y8XgmA0YigMgyng0okFMx+bgpq4UddfQGlqyfp8UoAjEYElWE4XaMi5Q19YzotfKi7L6B09bCjAsB9BJVh5GpUnBs5kx361sEsFfiPFVC6CSoAPEBQGYbTRz9S3tA3dlTgQ919Rz/JtKneVNrj1QAYbQgqw3AjqDQw9A0+lr+TwvEPALcRVIbRFs+cz7tSo0JQgQ/lhxOOfwC4jaAyDKfnqEj5Q9+oUYH/5IeTblqUAbiMoDIMV2pU2FGBj+WHE1qUAbiNoDIMV2pUajM1KocppoUP5YcTjn4AuI2gMoR4b0o9yUyXg7PFtJkdlfZEkm8E8B2KaQF4iaAyBGs3JWBIY8LOzVGpjYQUCWWeCi4nhN/kH/1QowLAbQSVIeQX0gYChmNfxzCM7K5KCwW18Bm6fgB4iaAyBDfqUyzZOhV2VOAzHP0A8BJBZQhu3PNjyU6nJajAZ7p66PoB4B2CyhBc3VHh6Ac+ZJpmv7qUODUqAFxGUBmCG8PeLA3ZoW/sqMA/4r397/bh6AeA2wgqQ3BzR4Whb/CjE496CCoA3EZQGYIXxbTcoAw/OTGYcPQDwG0ElSFkj36i7KhgdDoxmLCjAsBtBJUhuNn1Y9WofNyZUCptOv71gEKcGEwIKgDcRlAZgptHPxNqIgoYUtqUjnawqwJ/ODGYdPfSngzAXQSVIbR1Z/5RdiOoBAOGxlWHJUlHO3sc/3pAIU4MJkymBeA2gsoQ3NxRyf861pET4LXuHtqTAXiLoDIEt4OKNa+llaACn7Dak2sjmUs5uZQQgNsIKoPoSaaz/yi7vaNCUIFfWP8fGF+TOZbk6AeA2wgqg7DCgmFItdGQK1+THRX4jXXUM2EMQQWANwgqg7DCQm0kpEDAcOVr1scygYgaFfiFFUwm9F2a2dWbkmnSPg/APQSVQbh5z4+Fox/4jXX0Y+2opNKmelLpoT4EAGxFUBmEm8PeLAQV+I1VTDuuL6hIUryHoALAPQSVQbTFCSqA1Z5cF61SVTBzBNrF0DcALiKoDMLt1uT8r9UW5xsB/MEa+FYdDipWFZTELBUA7iKoDKK1y/2gQtcP/MYKJbFwUNXhvlkqBBUALiKoDMKLHRXrlmaCCvwiG1SqgoqFMzsqDH0D4CaCyiDo+gGkeF8o4egHgFcIKoPwpEalOvO1epLp7DcIwEv9j376dlR6qKEC4B6CyiC82FGpCYdkzZZjVwV+YNWjVIdDHP0A8ARBZRBe7KgEAgYFtfAVa45KrIqjHwDeIKgMor2vRdjNoJL/9RijDz/ozqtRyR39EFQAuIegMggvdlTyvx47KvBaOm0q3psZ+BYLBxXra09mRwWAmwgqA0im0upIeLOjQosy/CK/FiW/64caFQBuIqgMIH8ybF005OrXZkcFfpG/cxINcfQDwBsElQFYIaEmElIo6O5fEcW08AurRT5aFVAgYGS7frpoTwbgIoLKALyqT8n/mgQVeK0rrzVZEl0/ADxBUBmAFzNULAQV+EV+a7Kk7NEPwwgBuImgMoBsUHG5PkWiPRn+YRXNWkc+uaMfggoA97j/nbgMTKmL6uqzp2r2pBrXv3YuqFAHAG/lptJaOyq0JwNwH0FlAJ+aNV6fmjXek69dF8s8JRz9wGv5Nyfn/8rRDwA3cfTjM9SowC+6ezj6AeA9gorPEFTgF/nj8/N/JagAcBNBxWesoNLdm1JPMu3xajCa5Y5+MseRuYFv1E8BcA9BxWdqo7mWaHZV4CUrkFgBJX+Evmmanq0LwOhCUPGZYMBQbZSCWniva5AalbQpJdjtA+ASgooPZVuU4wQVeCc7R+WErh+J+34AuIeg4kMU1MIPTpyjEgoGFO67+6qLFmUALiGo+FBdlOm08F7XCUFFyh3/sKMCwC0lBZV//dd/1Zo1a7Kvf+Mb39DYsWN13nnnae/evbYtbrRiRwV+0JW9PTkXVKoJKgBcVlJQefDBBxWLxSRJb775plauXKmHH35YEydO1F133WXrAkejbFDpIqjAO/ETbk+W8oe+0aIMwB0ljdDfv3+/Zs+eLUl68cUX9Td/8zf6yle+ovPPP19Lliyxc32jUn01OyrwXldv//ZkqX+LMgC4oaQdlZqaGh09elSS9Oqrr+qSSy6RJEWjUXV3d9u3ulGKox/4wYntyRJHPwDcV9KOyqWXXqovf/nL+uQnP6kdO3bo8ssvlyS98847OvXUU+1c36hUR3syfCB+wqWEkhTjBmUALitpR+Xxxx9XU1OTDh8+rOeff14TJkyQJG3ZskVf/OIXbV3gaMSOCvygq/fkrp/qvtBCezIAt5S0ozJ27FitXLnypLd/73vfG/GCINVlJ9NSsAjvDHT0Y/0+zo4KAJeUtKPyyiuv6I033si+/vjjj+vss8/Wddddp2PHjtm2uNEqO5mWHRV4JJU2s5di9j/64QZlAO4qKajcfffdamtrkyRt27ZNX//613XZZZdp9+7dWrFiha0LHI04+oHX8rt68tuTc0c/7PYBcEdJRz979uzR/PnzJUnPP/+8rrjiCj344IN66623dNlll9m6wNHICiodiaSSqbRCQQYIw13WnBTDkKJVuf/+OPoB4LaSvgOGw2F1dXVJkn7zm99o6dKlkqTx48dnd1pQOqvrR5La4vzkCvd153X8GIaRfTtHPwDcVlJQueCCC7RixQo98MAD+sMf/pBtT96xY4emT59e8Odpbm7Wueeeq9raWjU0NOiaa67R9u3bS1lSRakKBjSm7xsCxz/wQtcArckSXT8A3FdSUFm5cqVCoZB++ctfatWqVZo2bZok6eWXX9Zf//VfF/x51q9fr+XLl2vjxo1au3atksmkli5dqs7OzlKWVVEoqIWXrBqV/I4fKVevwsA3AG4pqUZlxowZ+vWvf33S2//5n/+5qM/zyiuv9Hv96aefVkNDg7Zs2aLPfe5zJz0+kUgokUhkX6/kY6a6WJUOtMbZUYEnuge4OVmSokymBeCykoKKJKVSKb344ot67733ZBiG/uqv/kpXX321gsHg8B88iNbWVkmZWpeBNDc3j5pZLXV0/sBDuRkq/f+J4OgHgNtKCiq7du3SZZddpg8//FDz5s2TaZrasWOHGhsbtWbNGp1++ulFf07TNLVixQpdcMEFOuusswZ8zD333NOv/bmtrU2NjY2l/BF8jxZleMnq+olV9T8dzt31Q5E3AHeUFFS+9rWv6fTTT9fGjRuzux9Hjx7VDTfcoK997Wtas2ZN0Z/ztttu09tvv91vkNyJIpGIIpFIKUsuOwQVeCmeHZ/f/5+IKF0/AFxWUlBZv359v5AiSRMmTNBDDz2k888/v+jPd/vtt+ull17S66+/XlTXUCWjmBZeGmh8vpTbUYlz9APAJSUFlUgkovb29pPe3tHRoXA4XPDnMU1Tt99+u1544QWtW7dOs2bNKmU5FYkdFXjJCirVJ7Unc3syAHeV1J58xRVX6Ctf+Yp+//vfyzRNmaapjRs36tZbb9VVV11V8OdZvny5nn32Wf385z9XbW2tDh48qIMHD6q7u7uUZVWU7I5KnKAC93UPsqNivd7dm5Jpmq6vC8DoU1JQeeyxx3T66aerqalJ0WhU0WhU5513nmbPnq1HH3204M+zatUqtba2asmSJTrllFOyL88991wpy6oodTHrBmWCCtw32BwV63XTlBJ9lxYCgJNKOvoZO3asfvWrX2nXrl167733ZJqm5s+fr9mzZxf1efiJbHAc/cBLuaOf/v9E5E+q7epJKVpV+jgCAChEwUFluFuR161bl/39I488UvKCkEFQgZes9uNYuP+mazBgKBIKKJFMq6snqfFjCq9JA4BSFBxU/vjHPxb0uPwLzFC6bFDpIqjAfbmjn5P/iagOB5VIpplOC8AVBQeV1157zcl14ATWZNr2RFLptKlAgAAI9wzW9SNljn+OqTcbZgDASSUV08J51o6KaUrtcaaAwl2D3fUj5QpqaVEG4AaCik9FQkFF+8aX06IMt1khJDpAUOEGZQBuIqj4GAW18Ep2hP4gRz8SOyoA3EFQ8bG6KEEF3sjWqAxQTJs/9A0AnEZQ8TF2VOCV7O3JAx79cIMyAPcQVHyMoAKvDDaZNv9tHP0AcANBxccIKvBCbyqt3lRmavRQNSoc/QBwA0HFx+oIKvBAfgAZ+uiHoALAeQQVH2NHBV6wAkjAkCKhk/+JsKbVcvQDwA0EFR+zgkobQQUusgJIrCo44JUYtCcDcBNBxcc4+oEXrB2Vge75kXJHP3FqVAC4gKDiY+yowAvdvZm244HG50v5XT+0JwNwHkHFx6hRgRe6hrjnJ//tHP0AcANBxccIKvCCdfQTHaA1WaI9GYC7CCo+lj36iSdlmqbHq8FoYQWQ4Y5+aE8G4AaCio9ZQSWVNtWRoB4A7hj+6If2ZADuIaj4WLQqoHAw8xS1xQkqcEfXMEc/1VxKCMBFBBUfMwxDdbHMT6+tXdSpwB3x4Y5+qjj6AeAegorPMUsFbrPajqsHmaMSy9tRSaepnQLgLIKKz9H5A7dlJ9MO054sSfEkuyoAnEVQ8TmGvsFt3Xkj9AcSDeXeTkEtAKcRVHyOHRW4bbj25EDAULQq808HdSoAnEZQ8TmCCtw23NGPlKtfofMHgNMIKj6XG/pGUIE7uoeZoyJxgzIA9xBUfK4uyo4K3GV1/QxWoyIxnRaAewgqPsfRD9zW3ZuWJMUGaU+W8oe+MYgQgLMIKj7HHBW4rTs7R4WjHwDeI6j4HDsqcFvXMO3JUu7oh6ACwGkEFZ9jjgrcZnXyDN31k3lfnK4fAA4jqPhcfXVuR8U0GVcO5xXW9cMNygDcQVDxOWtHpTdlMrMCjutJppXsu7+numr4YlqCCgCnEVR8bkw4qGDAkCS1ddNhAWfltxtHw4P/85BrT+a/SQDOIqj4nGEYqotmfrKloBZOs3btggFD4eAQQaUq2O/xAOAUgkoZoPMHbrGGvVVXBWUYxqCP4+gHgFsIKmWAoAK3FHLPj5Q38I2gAsBhBJUywNA3uKWQ1mRJinL0A8AlBJUywI4K3NJdwLA3KXd7Mkc/AJxGUCkDBBW4pauAGSr57+foB4DTCCplgOm0cIt1yWD1EBcSSrmjny7akwE4jKBSBuoIKnCJtaMSHfboxxqhn3Z8TQBGN4JKGeDoB24pZHx+/vvZUQHgNIJKGSCowC2FBhVuTwbgFoJKGSCowC1dBbYnW11BiWRaqTSXZQJwDkGlDBBU4JZi25MlKc4sFQAOIqiUAYIK3FLo0U+0KiBrwj7HPwCcRFApA1bXTyKZ5qdXOCp39DN0e7JhGLmLCQkqABxEUCkDtZFQ9qfXtji7KnBOt3Up4TA7KhI3KANwB0GlDAQChmojmZ9wmaUCJ2Xv+hmmRkXK7/yhRRmAcwgqZaK+mjoVOK/Q25MlxugDcAdBpUxQUAs3FFpMK+V2XSimBeAkgkqZIKjADV0FtidLuV0XalQAOImgUiayQaWLoALndBc48E3KzVLh6AeAkwgqZSK3o0LhIpyTO/oZuj1ZopgWgDsIKmWiLtp3gzLtyXCIaZrZ0FFcezI3KANwDkGlTNRRowKHJZJpWdf2RAuoUcl1/bCjAsA5BJUyQTEtnJY/9bigHRVuUAbgAoJKmSCowGlW4KgKGqoKDv9PQ7Y9ma4fAA4iqJQJK6gwmRZOKaY1WcrtusTZUQHgIIJKmWBHBU7rLmIqbeZxmc4gjn4AOImgUiYIKnCaNUOlkNZkSarm6AeACwgqZcLq+unqSak3RTso7Ge1Jhd69BOj6weACwgqZaIumvsplzoVOKGYe34kRugDcAdBpUyEggHVRDJhheMfOKGY8flS3tEPNSoAHERQKSPUqcBJxXf9cNcPAOcRVMoI02nhpOKPfjL/fHD0A8BJBJUyUh/j6AfO6aI9GYAPEVTKCEPf4KRsjUpVce3JPcm0UtYlQQBgM0+Dyuuvv64rr7xSU6dOlWEYevHFF71cju9lg0qcdlDYr7uIm5Ol/jsvXbQoA3CIp0Gls7NTCxcu1MqVK71cRtmoi1KjAucUe/QTCQVkGJnfU6cCwCmF7fE6ZNmyZVq2bJmXSygr2a6fLoIK7NfVW1zXj2EYqq4KqrMnRecPAMd4GlSKlUgklEgksq+3tbV5uBr31VezowLnxIvs+pEyBbWdPSkKagE4pqyKaZubm1VfX599aWxs9HpJrmKOCpxU7NFP5rGBfh8LAHYrq6Byzz33qLW1Nfuyf/9+r5fkKuaowEldRV5KKEnVfR1CcWpUADikrI5+IpGIIpGI18vwDDsqcFJ3kZcSSrndF3ZUADilrHZURjvmqMBJxd71I+VCDe3JAJzi6Y5KR0eHdu3alX19z5492rp1q8aPH68ZM2Z4uDJ/stqT2xNJpdKmggHD4xWhkhQ7Qj//sRz9AHCKp0Fl8+bNuuiii7Kvr1ixQpJ000036ZlnnvFoVf5l7ahIUnu8V2Orwx6uBpWmq6SuH45+ADjL06CyZMkSmSajtwsVDgUUqwqquzel1m6CCuxjmmbeCP3id1QIKgCcQo1KmaGgFk5IJNOyfmYopUaFgW8AnEJQKTMEFTghf0ekmPZk6wZlRugDcApBpcwQVOAEq2snHAoUVaTN0Q8ApxFUygxD3+CEeAn1KVIuqHTTngzAIQSVMlMXy2y1t3XzjQH2KaXjR5KiVeyoAHAWQaXMcPQDJ5Ryz4+Ut6NCjQoAhxBUygxBBU6wunZKP/ohqABwBkGlzDBGH07o7uXoB4A/EVTKDDsqcELu6Ke4GZBWKzMj9AE4haBSZggqcILVtVNd4tEPOyoAnEJQKTMEFTih1GLa3F0/dKEBcAZBpcxYc1SOdfVwTxJsk73np9igUkXXDwBnEVTKzIzx1YqEAmqPJ7WzpcPr5aBCWF07pR799KZM9abStq8LAAgqZSZaFdSnT5sgSVq//bDHq0GlKHXgW/4ODLsqAJxAUClDS+ZOkiSt29Hi8Upgp8PtCc+O86ygEi0yqISDAVlXAzFLBYATCCplaMm8TFDZtOeYOhMUMVaCf3/rA537/d/o6d+978nXt9qLiz36MQwj26JMUAHgBIJKGZo1cYwax8fUk0rrzb8c9Xo5sMEbO49Ikn6364gnX9/q2qkuco6KlN/5Q1ABYD+CShkyDENL5jZI4vinUuxoae/3q9tKbU+W8u/7YXcPgP0IKmXKOv5Zt/0wbcplLpU2tauvg2v/x92ezCSxjn6Kvesn/2PYUQHgBIJKmWo6fYLCwYA+ONat3Uc6vV4ORmD/x12K9+Zae3cecr/tvNSuHym3C0ONCgAnEFTKVHU4pE/NGi8ps6uC8rXjUPuQr7vBnqMfggoA+xFUylju+Ic6lXJ24uA+Lwb5lTqZVpJiVZkCXI5+ADiBoFLGLuybp/L7PR+z7V7GrB2U6eNi/V53U24yLV0/APyFoFLGZjfUaNrYmHqSaW3cTZtyudp+MBNMrlgwVZK046C7QSWdNke0o2LNXolz9APAAQSVMmYYhi7k+KesJVNp7T6cKYa+/BOnSJIOtMbVHnfvdux4MhcwRlJMyw3KAJxAUClzF2bH6VNQW472ftylnlRasaqgzpxap4baiCR361Tyj2yipbQnc/QDwEEElTJ3/uyJqgoa2nu0S+/Tplx2dvbVo8yZXKNAwNC8KbX93u4Gqz4lEgooaF3cUwSOfgA4iaBS5moiIS2eabUpc/xTbrYfzOyczGmo7ffrDhdnqVj1KaUc+0jsqABwFkGlAmTrVDj+KTvWyPy5k2v6/epm509u2FvxHT/5H0dQAeAEgkoFsOapbNx9lO33MmMd8cyd3LejMtnaUXEzqGSKYKNVpf1zEAtnPo4WeQBOIKhUgHmTazWlLqp4b1q/3/Ox18tBgXqSuY6fuX21KdaOyqG2hFq73en8ifeObEfFGvjGZFoATiCoVADDMHLdP9SplI33j3YqmTZVEwlpan1UklQbrcr+3q2C2pGMz5dytS0c/QBwAkGlQljHP+upUykb1vHO7IYaGUau28Y6/tnuclAptZg2e9cPc1QAOICgUiHOnzNRwYCh3Yc7tf/jLq+XgwJYnT3WcY/Fet2tW5Sto59YCTNUpNzsFXZUADiBoFIh6qJVWjRjnCSOf8rFiYW0FrcLau06+qFGBYATCCoV5EKOf8rK9kGCyrzJ7s5SGfnRT18xLTsqABxAUKkgVp3Khr8cVSLJNw0/SyRT2ns0c0R3YlCZ3ZA5+jnSkdDHnT2Or8WqLSm96ycTcJJpUz3JtG3rAgCJoFJR5p9Sp0m1EXX1pLRpzzGvl4Mh7D7cqVTaVG00pMl1kX7vGxMJafq4mCR3jn+sI5tS7vmR+h8ZcfwDwG4ElQqS36a8fgd1Kn62I+/YJ7/jx2LtsrjRojzSo59wKKBQ3x1BHP8AsBtBpcJYxz/rtlOn4mc7BqlPscx1sU6le4RBRcq/74cWZQD2IqhUmAtmT1TAkHa2dOjD491eLweDGKw12eLmnT/WjkqpRz9Srk6FFmUAdiOoVJix1WF9sq9NeT27Kr41WGuyZW5ei7Jpmo6uZaS3J+d/LHdNAbAbQaUCLWGcvq/Fe1Pa2zeUb84gOyqnT6qRYUjHunp1pMPZzh97jn64QRmAMwgqFWjJvAZJ0u92HaFd1Id2tXTINKVx1VWaVBMZ8DGxcFAzx1dLcr6g1qorsS4XLEWs7+ZlggoAuxFUKtCZU+s0sSaszp6UtuylTdlvrLqTOYN0/FjcmlDbPcLJtFLe0LdeimkB2IugUoECAUOfm9N3/EObsu8MV0hryRbUtjjb+WNHjUosezEhO3gA7EVQqVBLzsgc//z6Tx8pmeKbh58MV0hryRbUHnT66GdklxJKuZBDezIAuxFUKtTS+ZM1YUxYHx7v1ivvHPR6Ocizo6WwoDKnwfnOn1TaVKKvjmlEOypV1o4KNSoA7EVQqVDRqqBu+MxMSdJTb+zxeDWwdCaS2v9xZr7NcEHltEljFAwYaosn1dKecGQ9+SPvR1KjEuMGZQAOIahUsBs+M1PhYEB/3Hecolqf2NVXbzKxJqzxY8JDPjZaFdTMCZnOH6cKavN3QKIhO45+CCoA7EVQqWCTaiO65pNTJUlPvbHb49VAyuv4aRh6N8Uyt+9x2x2qU+nOq08JBAbvQBpOtuuHoALAZgSVCnfLBadJkl7580Ht7xsyBu/sbCms48diPW6nQ3f+dPW1E4+kPkXKjd/v4ugHgM0IKhVu3pRafXbORKVN6ZkN73u9nFHP2hmZO6XAHZW+x1kFuHbrtuGeHykXdNhRAWA3gsoocMsFsyRJz23ar/Z4r8erGd0KbU22WI/bdajDkc4fO8bn5388A98A2I2gMgpcOHeSZjfUqCOR1HOb9nu9nFGrPd6rA61xSbnak+GcOmGMQgFD7YmkPur7WDt12RRUotyeDMAhBJVRwDCM7K7K0797nwFwHrHqUxpqI6qvriroY8KhgGZNHCNJ2u5A549VUzKS1mSJox8AziGojBL/45PTNL5vANx/vnPI6+WMStaE2XkF1qdYrDoVJy4njNswlVbKP/ohqACwF0FllIhWBXXDp2dIolXZK9YdP4W2JlvmZifU2t/5Y428t9qLS2XdvMzRDwC7EVRGkRuaMgPg3mIAnCd2ZkfnF9aabMm1KPv36CfG0Q8AhxBURpGG2qiuPjszAO5/M1bfddlhbwV2/Fisx+841KF02t7On24Hjn6cupcIwOhEUBllbvlspqj25T9/xAA4F7V29epQW+a+nmJ3VE6dUK1wMKDu3pQ+PN5t67rsak+2dlRSaVM9FGsDsBFBZZQ5Y0qdLpidGQD3rwyAc401sG1qfVS10cI6fiyhYECnTcp0/th9549tRz95OzIc/wCwE0FlFGIAnPtKPfaxzJ3sTEGtXTsqVcGAqoKZu4IoqAVgJ4LKKHTh3Ek6fdIYtSeS+sXmD7xezqhg3dVT7LGPxfo423dU+rp+Rlqjkv85aFEGYCeCyigUCBjZywqf/t0epWwu0MTJsnf8lLijkiuotTeodPdm6kliI2xPlrhBGYAzCCqj1P88Z5rGVVfpg2PdevWdg14vp+LlWpNLCyrzrDt/WjpsDZbdPfbcnizl6lw4+gFgJ4LKKBWtCuqGz8yUJP0LrcqO+rizR0c6eiRJsxtKO/ppHF+tSCigRDJta7eWFSpGWkwrcfQDwBkElVHsxr4BcFv2HtNr21u8Xk7Fso5rpo+LaUyktCOWYMDIhhw7j3+sUGFHjUruvh9uUAZgH4LKKNZQG9VVfQPg/tfTm/Sl//0H/X73UY9XVXmsYFHqsY9lrgN1KnZ1/Ugc/QBwxsgr6FDWvn3FfKXTpn71pwN6fcdhvb7jsM49dZy+etFsLZk7SYZheL3Esmd/ULGvRbnLzqBSRVABYD/Pd1SeeOIJzZo1S9FoVIsWLdJvf/tbr5c0qtTHqvTIF87Wa19fous/PUPhYECb3j+m//X0Jl258g29vO0j28e2jzY7RtiabHGiRTk7Qt+Wrp9MUIlTowLARp7uqDz33HO688479cQTT+j888/Xj3/8Yy1btkzvvvuuZsyY4eXSRp0ZE6r1/f/xCX3t4jn6yeu79X9+v09//rBNf/9/3tLpk8boq0tm66qzp6oqmMm2qbSp7t6UuhJJdfWk+l4yvw8FDE0dG9MpY6OKhEb+k3qpkqm03j/apR2H2rXjULt2HurQ4Y6ETps4RnMm12re5FrNnVyjSbURx3aOTNPMXiZo147K7sOdSqbSCgVH9nNGMpXOjru3ZY5KmBuUAdjP06DyyCOP6JZbbtGXv/xlSdKjjz6q//zP/9SqVavU3Nzs5dJGrcl1UX3rivn66kWz9czv9uiZDe/rL4c79fV/+5Pu//W7CgYMdfUkFe8t7D6XSbURTR0b0/SxMU0bF9PU+qimjavW1LFR1RU5Sn4oiWRauw93aGdLh7YfzAST3Yc7B7x35g97Pu73+tjqKs1tqNXcKTWaO7lWcyfXatrYmIbLLvl371m/N2Xm/V463tWjY129Mgzp9Ekj21GZNjamWFVQ3b0pbXr/mBrHx4Z8fDot9aTS6kmm1ZvKvPQk09m3dSRyRa92Hv20tMf1wTHukSqGaWb+G26P96otnlR7vFft/X5Nqi3eq454UlWhgOqiIdVGq1QbCanW+n2/X0MKBji2hT1iVUFNqIl49vU9Cyo9PT3asmWLvvnNb/Z7+9KlS7Vhw4YBPyaRSCiRSGRfb2trc3SNo9n4MWGtWDpP/9/nTtPPNu7VU7/do6OdPSc9zjCk6qqgqiMhVYeDqg6H1JPMXJ4X703rcHtCh9sT+tP+4+7/IZT5BjynIRdAJtaGtedwp3Yc6tCOQ+16/2injnf16g/vf6w/vP/x8J+wRDPHV4+4BTgQMDRnco3e/qBVX/zJRptWJlUFDUVCIz8FtsLOsxv36dmN+0b8+QD4w1ULp+qxL37Ss6/vWVA5cuSIUqmUJk+e3O/tkydP1sGDAw8ga25u1ve+9z03loc+tdEqfXXJbN18/iztONSuSCjYF0iCGhMJKRIKDHhsYpqmjnX16sNj3frweN/LsW4dOJ57vavANlZDw/9kGAwYmjG+WvOm1GrO5Jq+Y53MzkhgiJ8s470p/eVwJrRsP9ihnYfa9d8H23WkIzHox/Rbm5Fbo2FIhpT9+zD6/icUMLIza0bq2sWN2n24U70F3FAcMAyFQwFVBQOKhDJ38VivVwUDCocCCgcDWnrmZFuOvi46Y5JWc39UySKhQHZHpC5vZ6QultstqYmE1JtK99ttacv+mntbRzyptEltGewRCnq7O2eYpjf/NR84cEDTpk3Thg0b1NTUlH3797//ff3sZz/Tf//3f5/0MQPtqDQ2Nqq1tVV1dXWurBsAAIxMW1ub6uvrC/r+7dmOysSJExUMBk/aPWlpaTlpl8USiUQUiXh3TgYAANzlWXtyOBzWokWLtHbt2n5vX7t2rc477zyPVgUAAPzE066fFStW6MYbb9TixYvV1NSkJ598Uvv27dOtt97q5bIAAIBPeBpUvvCFL+jo0aO6//779dFHH+mss87Sf/zHf2jmTHsKDwEAQHnzrJjWDsUU4wAAAH8o5vu35yP0AQAABkNQAQAAvkVQAQAAvkVQAQAAvkVQAQAAvkVQAQAAvkVQAQAAvkVQAQAAvkVQAQAAvuXpCP2RsobqtrW1ebwSAABQKOv7diHD8cs6qLS3t0uSGhsbPV4JAAAoVnt7u+rr64d8TFnf9ZNOp3XgwAHV1tbKMAxbP3dbW5saGxu1f/9+7hHyEM+DP/A8+APPgz/wPIycaZpqb2/X1KlTFQgMXYVS1jsqgUBA06dPd/Rr1NXV8R+iD/A8+APPgz/wPPgDz8PIDLeTYqGYFgAA+BZBBQAA+BZBZRCRSETf+c53FIlEvF7KqMbz4A88D/7A8+APPA/uKutiWgAAUNnYUQEAAL5FUAEAAL5FUAEAAL5FUAEAAL5FUBnAE088oVmzZikajWrRokX67W9/6/WSKtrrr7+uK6+8UlOnTpVhGHrxxRf7vd80TX33u9/V1KlTFYvFtGTJEr3zzjveLLaCNTc369xzz1Vtba0aGhp0zTXXaPv27f0ew3PhvFWrVmnBggXZYWJNTU16+eWXs+/nOfBGc3OzDMPQnXfemX0bz4U7CConeO6553TnnXfqvvvu0x//+Ed99rOf1bJly7Rv3z6vl1axOjs7tXDhQq1cuXLA9z/88MN65JFHtHLlSm3atElTpkzRpZdemr3rCfZYv369li9fro0bN2rt2rVKJpNaunSpOjs7s4/huXDe9OnT9dBDD2nz5s3avHmzPv/5z+vqq6/OfgPkOXDfpk2b9OSTT2rBggX93s5z4RIT/XzqU58yb7311n5vO+OMM8xvfvObHq1odJFkvvDCC9nX0+m0OWXKFPOhhx7Kvi0ej5v19fXmj370Iw9WOHq0tLSYksz169ebpslz4aVx48aZ//Iv/8Jz4IH29nZzzpw55tq1a80LL7zQvOOOO0zT5P8PbmJHJU9PT4+2bNmipUuX9nv70qVLtWHDBo9WNbrt2bNHBw8e7PecRCIRXXjhhTwnDmttbZUkjR8/XhLPhRdSqZRWr16tzs5ONTU18Rx4YPny5br88st1ySWX9Hs7z4V7yvpSQrsdOXJEqVRKkydP7vf2yZMn6+DBgx6tanSz/t4Hek727t3rxZJGBdM0tWLFCl1wwQU666yzJPFcuGnbtm1qampSPB5XTU2NXnjhBc2fPz/7DZDnwB2rV6/WW2+9pU2bNp30Pv7/4B6CygAMw+j3ummaJ70N7uI5cddtt92mt99+W2+88cZJ7+O5cN68efO0detWHT9+XM8//7xuuukmrV+/Pvt+ngPn7d+/X3fccYdeffVVRaPRQR/Hc+E8jn7yTJw4UcFg8KTdk5aWlpNSM9wxZcoUSeI5cdHtt9+ul156Sa+99pqmT5+efTvPhXvC4bBmz56txYsXq7m5WQsXLtQPf/hDngMXbdmyRS0tLVq0aJFCoZBCoZDWr1+vxx57TKFQKPv3zXPhPIJKnnA4rEWLFmnt2rX93r527Vqdd955Hq1qdJs1a5amTJnS7znp6enR+vXreU5sZpqmbrvtNv37v/+7/uu//kuzZs3q936eC++YpqlEIsFz4KKLL75Y27Zt09atW7Mvixcv1vXXX6+tW7fqtNNO47lwCUc/J1ixYoVuvPFGLV68WE1NTXryySe1b98+3XrrrV4vrWJ1dHRo165d2df37NmjrVu3avz48ZoxY4buvPNOPfjgg5ozZ47mzJmjBx98UNXV1bruuus8XHXlWb58uX7+85/rV7/6lWpra7M/KdbX1ysWi2VnSPBcOOvee+/VsmXL1NjYqPb2dq1evVrr1q3TK6+8wnPgotra2mx9lmXMmDGaMGFC9u08Fy7xruHIvx5//HFz5syZZjgcNs8555xseyac8dprr5mSTnq56aabTNPMtAF+5zvfMadMmWJGIhHzc5/7nLlt2zZvF12BBnoOJJlPP/109jE8F867+eabs//+TJo0ybz44ovNV199Nft+ngPv5LcnmybPhVsM0zRNjzISAADAkKhRAQAAvkVQAQAAvkVQAQAAvkVQAQAAvkVQAQAAvkVQAQAAvkVQAQAAvkVQAQAAvkVQAVBR1q1bJ8MwdPz4ca+XAsAGBBUAAOBbBBUAAOBbBBUAtjJNUw8//LBOO+00xWIxLVy4UL/85S8l5Y5l1qxZo4ULFyoajerTn/60tm3b1u9zPP/88zrzzDMViUR06qmn6gc/+EG/9ycSCX3jG99QY2OjIpGI5syZo6eeeqrfY7Zs2aLFixerurpa5513nrZv3+7sHxyAIwgqAGz1rW99S08//bRWrVqld955R3fddZduuOEGrV+/PvuYu+++W//0T/+kTZs2qaGhQVdddZV6e3slZQLGtddeq7/927/Vtm3b9N3vflff/va39cwzz2Q//ktf+pJWr16txx57TO+9955+9KMfqaampt867rvvPv3gBz/Q5s2bFQqFdPPNN7vy5wdgM49vbwZQQTo6OsxoNGpu2LCh39tvueUW84tf/KL52muvmZLM1atXZ9939OhRMxaLmc8995xpmqZ53XXXmZdeemm/j7/77rvN+fPnm6Zpmtu3bzclmWvXrh1wDdbX+M1vfpN925o1a0xJZnd3ty1/TgDuYUcFgG3effddxeNxXXrppaqpqcm+/PSnP9Vf/vKX7OOampqyvx8/frzmzZun9957T5L03nvv6fzzz+/3ec8//3zt3LlTqVRKW7duVTAY1IUXXjjkWhYsWJD9/SmnnCJJamlpGfGfEYC7Ql4vAEDlSKfTkqQ1a9Zo2rRp/d4XiUT6hZUTGYYhKVPjYv3eYppm9vexWKygtVRVVZ30ua31ASgf7KgAsM38+fMViUS0b98+zZ49u99LY2Nj9nEbN27M/v7YsWPasWOHzjjjjOzneOONN/p93g0bNmju3LkKBoP6xCc+oXQ63a/mBUDlYkcFgG1qa2v1D//wD7rrrruUTqd1wQUXqK2tTRs2bFBNTY1mzpwpSbr//vs1YcIETZ48Wffdd58mTpyoa665RpL09a9/Xeeee64eeOABfeELX9Cbb76plStX6oknnpAknXrqqbrpppt0880367HHHtPChQu1d+9etbS06Nprr/Xqjw7AIQQVALZ64IEH1NDQoObmZu3evVtjx47VOeeco3vvvTd79PLQQw/pjjvu0M6dO7Vw4UK99NJLCofDkqRzzjlHv/jFL/SP//iPeuCBB3TKKafo/vvv19/93d9lv8aqVat077336qtf/aqOHj2qGTNm6N577/XijwvAYYaZf/gLAA5at26dLrroIh07dkxjx471ejkAygA1KgAAwLcIKgAAwLc4+gEAAL7FjgoAAPAtggoAAPAtggoAAPAtggoAAPAtggoAAPAtggoAAPAtggoAAPAtggoAAPCt/x9CuvWwFBMZIwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(epoch_train_loss)), epoch_train_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset the weights learned from the overfitting experiment and perform actual train and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m avg_train_loss \u001b[39m=\u001b[39m train()\n\u001b[1;32m      2\u001b[0m avg_test_loss, accuracy \u001b[39m=\u001b[39m predict()\n",
      "Cell \u001b[0;32mIn[23], line 24\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     23\u001b[0m     \u001b[39m# Update weights by stepping in direction of min gradients\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     26\u001b[0m avg_train_loss\u001b[39m.\u001b[39mappend(train_loss\u001b[39m/\u001b[39mBATCH_SIZE)\n\u001b[1;32m     27\u001b[0m scheduler\u001b[39m.\u001b[39mstep(train_loss\u001b[39m/\u001b[39mBATCH_SIZE)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlmodels/lib/python3.11/site-packages/torch/optim/adam.py:393\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m--> 393\u001b[0m param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_train_loss = train()\n",
    "avg_test_loss, accuracy = predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
